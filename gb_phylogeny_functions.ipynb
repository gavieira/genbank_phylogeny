{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genbank phylogeny from multiple genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing everything we'll need\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "import os, glob, itertools, tarfile, subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequences obtained using code in the 'download_accessions.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_name):\n",
    "    os.makedirs(os.path.dirname(dir_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_taxdb():\n",
    "    taxdb_dir = \"{}/taxdb/\".format(os.getcwd())\n",
    "    if not (os.path.exists(\"{}/taxdb.btd\".format(taxdb_dir)) and os.path.exists(\"{}/taxdb.bti\".format(taxdb_dir))):\n",
    "        print(\"taxdb files (taxdb/taxdb.btd e taxdb/taxdb.bti) not found. Extracting taxdb database...\")\n",
    "        create_dir(taxdb_dir)\n",
    "        tarfile.open(\"{}/taxdb.tar.gz\".format(os.getcwd()), \"r:*\").extractall(taxdb_dir)\n",
    "    os.putenv(\"BLASTDB\", taxdb_dir)\n",
    "setup_taxdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blastn(fasta):\n",
    "    blast_output = \"{}.blast\".format(os.path.splitext(fasta)[0]) #Get fasta name without extension\n",
    "    #blastn = NcbiblastnCommandline(cmd=\"blastn\", query=fasta, db='nr', remote=True, outfmt=\"6 qseqid staxids sscinames sacc sseq\",\n",
    "    #                     max_target_seqs=5000, entrez_query=\"Formicidae [Organism]\", out=blast_output)\n",
    "    subprocess.run('blastn -query {} -db nr -max_target_seqs 5000 -remote \\\n",
    "    -entrez_query \"Formicidae [Organism]\" -outfmt \"6 qseqid staxids sscinames sacc sseq\"\\\n",
    "    -out {}'.format(fasta, blast_output), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_blast_searches(directory):\n",
    "    setup_taxdb()\n",
    "    extensions = [\".fa\", \".fasta\"]\n",
    "    for extension in extensions:\n",
    "        for fasta in glob.glob(\"{}*{}\".format(directory, extension)):\n",
    "            print(fasta)\n",
    "            run_blastn(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/EF1/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/EF2/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/18S/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/COX1/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/28S/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/abdA/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/LWR/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/WNT/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/CYTB/\n",
      "/home/gabriel/Dropbox/repos/genbank_phylogeny/seed_fasta/12S/\n"
     ]
    }
   ],
   "source": [
    "# Finallly running blast for all seeds\n",
    "# Não roda com sequências que tenham Ns\n",
    "\n",
    "for directory in glob.glob(\"{}/seed_fasta/*/\".format(os.getcwd())):\n",
    "    print(directory)\n",
    "#    run_all_blast_searches(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the blast results into dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(blast_result):\n",
    "    return pd.read_csv(blast_result, sep='\\t',\n",
    "               names=['qseqid', 'staxids', 'sscinames', 'sacc', 'sseq']) \n",
    "    \n",
    "def extract_columns_dataframe(df):\n",
    "    df = df[['qseqid', 'staxids', 'sscinames', 'sacc', 'sseq']]\n",
    "    df['sseq'] = df['sseq'].apply(lambda x: x.replace('-', ''))\n",
    "    #df['sseqlen'] = len(df['sseq'])\n",
    "    df['sseqlen'] = df.apply(lambda row: len(row.sseq), axis = 1) \n",
    "    df = df[['qseqid', 'staxids', 'sscinames', 'sacc', 'sseqlen', 'sseq']]\n",
    "    return df\n",
    "    \n",
    "#df = extract_columns_dataframe(create_dataframe('seed_fasta/COX1/Formica_fusca_coi.blast'))\n",
    "#print(dir(df[\"sscinames\"].str))\n",
    "#print(df.sscinames.str.contains(\"\\.\"))\n",
    "\n",
    "#df.head(n=100)\n",
    "#df.to_excel(\"blast.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the blast results in a dataframe, we can clean it in order to:\n",
    "\n",
    "-  Remove rows with more than one taxid;\n",
    "-  Sort dataframe (descending) for both taxid and sseqlen;\n",
    "-  Keep only one record by taxid (the one with the longest sseqlen);\n",
    "-  Remove species with unwanted characters (\".\", \":\", and \"-\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    #clean_df = df.drop(df[df.staxids.str.contains(\";\")].index) # Removing rows with hybrid sequences (more than one taxid value)\n",
    "    clean_df = df.dropna() # Removes rows with NaN value(s)\n",
    "    #clean_df[\"staxids\"] = pd.to_numeric(clean_df[\"staxids\"])\n",
    "    clean_df = clean_df.sort_values(by=[\"staxids\", \"sseqlen\"], ascending=False) # Sorting dataframe by taxid and sseqlen (descending) - Guarantees that highest sseqlen will always be the first row for that taxid\n",
    "    clean_df = clean_df.drop_duplicates(subset=\"staxids\", keep='first') # Keeps only one record per txid. The one that has the highest sseqlen\n",
    "    for non_valid_ssciname in [\"\\.\", \"\\:\", \"\\-\", \"\\;\"]:\n",
    "        clean_df = clean_df[~clean_df.sscinames.str.contains(non_valid_ssciname)] # Removes columns with sscinames containing the characters in the list\n",
    "    return clean_df\n",
    "\n",
    "#clean_dataframe(df).to_csv(\"clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the functions to extract and clean the data, we have to concatenate the blast results into a single, final dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_blast_dataframes(directory):\n",
    "    blast_data = []\n",
    "    for blast_result in glob.glob(\"{}/*.blast\".format(directory)):\n",
    "        blast_data.append(clean_dataframe(extract_columns_dataframe(create_dataframe(blast_result))))\n",
    "    return pd.concat(blast_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a matrix with the percentage of hits shared between all sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the number of subject accessions shared between two species\n",
    "\n",
    "def matrix_absolute_matches(blast_full_dataframe):\n",
    "    blast_dict = {k: f.tolist() for k, f in blast_full_dataframe.groupby('qseqid')['sacc']}\n",
    "    matrix_dict = {k: [] for k in blast_dict.keys()} #Empty \n",
    "    for pair in itertools.product(blast_dict.keys(), repeat=2): #All possible combinations\n",
    "        match = 0\n",
    "        for acc in blast_dict[pair[0]]:\n",
    "            if acc in blast_dict[pair[1]]:\n",
    "                match += 1\n",
    "        matrix_dict[pair[0]].append(match)\n",
    "    return pd.DataFrame(matrix_dict, index=matrix_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's create 3 final fasta files:\n",
    "\n",
    "1. With all query sequences\n",
    "2. With all unique subject sequences from the blast searches\n",
    "1. With all query + subject sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queries_to_multifasta(directory):\n",
    "    #create_dir(\"final_seqs/\")\n",
    "    with open(\"./final_seqs/queries.fa\", \"w\") as queries:\n",
    "        for fasta in glob.glob(\"{}/*fa\".format(directory)):\n",
    "            for record in SeqIO.parse(fasta, \"fasta\"):\n",
    "                queries.write(record.format(\"fasta\"))\n",
    "\n",
    "def subjects_to_multifasta(blast_full_dataframe, results_dir, gene_name):\n",
    "    #create_dir(\"final_seqs/\")\n",
    "    unique_blast_subjects = blast_full_dataframe.sort_values(by=[\"sseqlen\"], ascending=False).drop_duplicates(subset=\"staxids\", keep='first') # Keep only largest sequence per taxid\n",
    "    with open(\"{}/{}_subjects.fa\".format(results_dir,gene_name), \"w\") as subjects:\n",
    "        for row in unique_blast_subjects.itertuples(): # Awfully slow. Need to optimize this later\n",
    "            subjects.write(\">{}_{}\\n{}\\n\".format(row.sscinames.replace(\" \", \"_\"), row.sacc, row.sseq))\n",
    "        #unique_blast_subjects.apply(lambda x: subjects.write(\">{}_{}\\n{}\".format(x['sscinames'].replace(\" \", \"_\"), x[\"sacc\"], x['sseq'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining all these functions, it is time to run the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EF1\n",
      "EF2\n",
      "18S\n",
      "COX1\n",
      "28S\n",
      "abdA\n",
      "LWR\n",
      "WNT\n",
      "CYTB\n",
      "12S\n"
     ]
    }
   ],
   "source": [
    "# Finallly running blast for all seeds\n",
    "# Não roda com sequências que tenham Ns\n",
    "\n",
    "results_dir = \"{}/seed_fasta/results\".format(os.getcwd())\n",
    "create_dir(results_dir + '/')\n",
    "for directory in glob.glob(\"{}/seed_fasta/*\".format(os.getcwd())):\n",
    "    gene_name = os.path.basename(directory)\n",
    "    if gene_name != os.path.basename(results_dir):\n",
    "        print(\"Getting subject seqs for {} seed\".format(gene_name))\n",
    "        full_dataframe = merge_blast_dataframes(directory)\n",
    "        full_dataframe.to_csv(\"{}_teste.csv\".format(gene_name))\n",
    "        subjects_to_multifasta(full_dataframe, results_dir, gene_name)\n",
    "        matrix_absolute_matches(full_dataframe).to_excel(\"{}/{}_matrix.xlsx\".format(results_dir,gene_name), \n",
    "                                                         index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty much it!!! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
